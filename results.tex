%!TEX root = thesis.tex
%% %% ***************** Results *****************


\section{Results}\label{sec:results}

This section presents the results of the HML pipeline combinations.
The values of algorithm evaluations are compared
and the results are judged.
Before that,
we discuss the encountered memory issue
that affected our pipeline component choices.

After presenting the results,
the sensibility of the outcome is evaluated
and suggestions for improvement are made.


%% ************************************************************************************************************


\subsection{Memory issues and limitations}\label{subsec:res-memory-issues}

Memory is a crucial resource in ML training.
Algorithms take multiple steps while iterating the data
and intermediate results are stored in the RAM rather than on the disk.
While building an ML pipeline in Azure ML Studio,
a memory issue emerged
that affected several components
and caused serious limitations
in terms of usable components and data size.
Due to the time limits of this study,
this issue was not resolved
and the problem causing it was not found.
As several conditions related to the environment costs
were already issued by the company,
we could not acquire more expensive computing instances
with more memory capacity to confirm
whether the issue was related to compute instance property limitations.

In order to complete some of the ML pipeline runs
the data amount had to be reduced to 600 megabytes.
This was considerably less than what was assumed to be sufficient
for reliable results,
as this size of data would cover just a few months of logging.
To increase the time span of log data,
it was decided that the info-type log messages were to be trimmed from the data.
This way we were able to reduce the data to 8.6 million log rows
which was about 10\% of the original data size.
Before the final cleaning operations,
the data took 8.1GB of disk space,
and after cleaning the rawmessage-field with the script in appendix~\ref{sec:app-data-cleaning-script},
the final size of the data on the disk was 6.6GB\@.
Even with this data size,
some Azure ML components still ran into memory issue
and we were forced to choose components
that were able to handle these data amounts.

One of the most sensitive components for this issue
was the n-gram feature extraction module.
As we explained in section~\ref{subsec:bg-ngram-features-and-hashing},
each new n-gram or word creates a new column in the data.
This module suffered greatly from the memory exhaustion,
especially while processing rawmessage
which included more data in the JSON structure than the pure message-field.
With rawmessage,
n-gram feature extraction was able to handle
less than 1\% of the data amount,
resulting to more than 1000 columns of n-gram feature columns.
With message data,
the situation was just slightly better,
as the limit of data amount was at 2\%.

The feature hashing component was able to process more data than the pure n-gram feature extracting module,
but this required the compression level to be quite high.
The main parameter to tune in feature hashing was the bitsize of the hashing.
The smaller the hashing bitsize was,
the greater the level of compression was,
which resulted to more lost information.
In order to utilize this module at all,
the hashing bitsize had to be set to 7
which produced approximately 130 hashed feature columns.

With some component combinations,
additional data split modules were needed
in order to finish the ML pipeline.
For example,
with the rawmessage-data, feature hashing and unconventional training,
the validation data had to be trimmed to 70\%
so that the model scoring could be executed.


%% ************************************************************************************************************

\subsection{Algorithm estimation results}\label{subsec:res-algorithm-estimation-results}

Based on the first pipeline experiments,
the Decision Forest Regression algorithm gave the most promising results.
For this reason,
the values listed in this section are based on the use of this algorithm unless otherwise stated.
However, this first impression was a misinterpretation,
as the final results show.
For unknown reasons,
when time frame compression was carried out with SQL queries instead of R-script,
the results were considerably better.
However, these results could not be relied on,
as further investigation showed that the time frame compression was done incorrectly.
This was verified by calculating the total number of log rows
and comparing it to the sum of the line counts in all time frames.
As something did not work as intended with SQL queries,
the SQL-based time frame compression was decided to reject.
It was also much easier to include more statistical metrics
with R-scripting than with SQL queries.

As explained in section~\ref{subsec:pipe-branching},
the number of pipeline component combinations to compare was significant.
Initial experiments were decided to run with a few basic component combinations
and select the most promising branches to continue with.
For this reason,
pure n-gram feature extraction was rejected in the final analysis
because the memory issue greatly affected its reliability in terms of the amount of data.
Feature hashing, however,
could be included.
The amount of data was seen sufficient to consider the results reliable,
although, to make this possible,
a lot of information was lost due to the level of compression used.

In table~\ref{tab:results-decision-forest-all},
the final results of the pipelines using Decision Forest Regression algorithm in phase 2
are listed for comparison.
When interpreting the comparison metrics,
the focus was on the coefficient of determination (CoD-value),
mean absolute error (MAE-value),
and their difference with the corresponding metrics
in cases where the anomaly probability value was omitted from phase 2.
Like we explained in section~\ref{subsec:pipe-branching},
we assumed that anomaly probability values calculated by the anomaly detection algorithm
provide valuable information for ticket count estimation.
Thus,
if these values are removed before phase 2 algorithm training,
the estimation capabilities of the algorithm should weaken.
Hence,
we decided to experiment more with the pipeline component combinations
that resulted in noticeably better results
than their anomaly-probability-omitted counterparts.
As mentioned in the previous section,
with MAE smaller is better,
whereas with CoD bigger is better.

\begin{table}[htb]
    \begin{tabularx}{\textwidth}{|Y|L{0.091\textwidth}|L{0.096\textwidth}|L{0.077\textwidth}|L{0.077\textwidth}|L{0.105\textwidth}|}
        \hline
        \multicolumn{6}{|c|}{\textit{Component combinations with Decision Forest regression}} \\
        \hline
        \textbf{Combination} &
        \textbf{MAE} &
        \textbf{RMSE} &
        \textbf{RSE} &
        \textbf{RAE} &
        \textbf{CoD} \\ \hline
        Msg PropT           				& 3.6875				& 4.2886					& 1.6966					& 1.3169					& -0.6966		\\
        Msg PropT NA	     				& 3.5125				& 4.2718					& 1.6834					& 1.2544					& -0.6834		\\
        \hline
        Msg UnconT             				& 3.5236				& 4.3578					& 1.3493					& 1.1313					& -0.3493		\\
        Msg UnconT NA         				& 4.0405				& 4.8958					& 1.7030					& 1.2972					& -0.7030		\\
        \hline
        PreP.Msg PropT     					& 3.25  				& 3.7720					& 1.3125					& 1.1607					& -0.3125		\\
        PreP.Msg PropT NA            		& 3.5125				& 4.2718					& 1.6834					& 1.2544					& -0.6834		\\
        \hline
        PreP.Msg UnconT       				& 3.7905				& 4.5707					& 1.4843					& 1.2169					& -0.4843		\\
        PreP.Msg UnconT NA           		& 4.0405				& 4.8958					& 1.7030					& 1.2972					& -0.7030		\\
        \hline
        \textbf{Msg FHash PropT }   		& 2.4875				& 2.8611					& 0.7551					& 0.8883					& \textbf{0.24484}		\\
        Msg FHash PropT NA  				& 2.85  				& 3.1922					& 0.9400					& 1.0178					& \textbf{0.05990}		\\
        \hline
        Msg FHash UnconT        			& 2.6071				& 3.2484					& 0.7234					& 0.8488					& 0.27657		\\
        Msg FHash UnconT NA        			& 2.6562				& 3.2593					& 0.7282					& 0.8648					& 0.27171		\\
        \hline
        PreP.Msg FHash PropT	   			& 3.05  				& 3.4058					& 1.0701					& 1.0892					& -0.0701		\\
        PreP.Msg FHash PropT NA  			& 2.6   	 			& 2.8858					& 0.7682					& 0.9285					& 0.23172		\\
        \hline
        PreP.Msg FHash UnconT	       		& 2.7901				& 3.4467					& 0.8144					& 0.908						& 0.18556  		\\
        PreP.Msg FHash UnconT NA      		& 2.8616				& 3.4125					& 0.7983					& 0.9316					& 0.20162 		\\
        \hline
        \textbf{RawMsg PropT}       		& \textbf{1.3611}		& 1.8263					& 1.6678					& 1.0208					& -0.6678		\\
        RawMsg PropT NA           			& \textbf{2.5833}		& 2.8694					& 4.1168					& 1.9375					& -3.1168		\\
        \hline
        \textbf{RawMsg UnconT }        		& 2.9   				& 3.8200					& 0.7859					& 0.7928					& \textbf{0.21402}		\\
        RawMsg UnconT NA              		& 3.0733				& 3.9588					& 0.8441					& 0.8402					& \textbf{0.15588}		\\
        \hline
        \textbf{PreP.RawMsg PropT }  		& \textbf{0.5277}		& 0.6328					& 0.2002					& 0.3958					& \textbf{0.79976}		\\
        PreP.RawMsg PropT NA        		& \textbf{2.5833}		& 2.8694					& 4.1168					& 1.9375					& \textbf{-3.1168}		\\
        \hline
        \textbf{PreP.RawMsg UnconT}    		& 2.9466				& 3.7159					& 0.7437					& 0.8056					& \textbf{0.25627}		\\
        PreP.RawMsg UnconT NA             	& 3.0733				& 3.9588					& 0.8441					& 0.8402					& \textbf{0.15588}		\\
        \hline
        RawMsg FHash PropT					& 3.7916				& 5.3078					& 2.6361					& 1.3787					& -1.6361		\\
        RawMsg FHash PropT NA        		& 4.0625				& 5.2026					& 2.5326					& 1.4772					& -1.5326		\\
        \hline
        RawMsg FHash UnconT    				& 2.875 				& 3.3994					& 1.0458					& 1.0267					& -0.0458		\\
        RawMsg FHash UnconT NA         		& 2.9   				& 3.8249					& 1.3240					& 1.0357					& -0.3240		\\
        \hline
        PreP.RawMsg FHash PropT				& 2.8194				& 2.8993					& 1.4834					& 1.4097					& -0.4834		\\
        PreP.RawMsg FHash PropT NA    		& 2.5694				& 3.0503					& 1.6419					& 1.2847					& -0.6419		\\
        \hline
        PreP.RawMsg FHash UnconT			& 2.6153				& 3.4303					& 0.8327					& 0.9324					& 0.16723		\\
        PreP.RawMsg FHash UnconT NA	    	& 2.5384				& 3.1784					& 0.7149					& 0.9050					& 0.28503		\\
        \hline
    \end{tabularx}
    \caption{Results of HML pipeline with Decision Forest regression algorithm in phase 2.
        \textbf{FHash} means \textit{Feature Hashing},
        \textbf{PropT} indicates \textit{proper training},
        \textbf{UnconT} that \textit{unconventional training} is done in phase 1,
        \textbf{PreP.} means that \textit{text preprocessing} has been used, and
        \textbf{NA} means that \textit{anomaly values has been removed} for comparison (NoAnomalies).
        The most promising comparison metrics and their component combinations are bolded.
    }
    \label{tab:results-decision-forest-all}
\end{table}

As highlighted in table~\ref{tab:results-decision-forest-all},
the most promising results were achieved by using:
\begin{itemize}
    \setlength\itemsep{0pt}
    \setlength{\parskip}{0pt}
    \item message data, feature hashing and proper training
    \item rawmessage data and unconventional training
    \item rawmessage data and proper training
    \item rawmessage data, preprocessed, proper training, and
    \item rawmessage data, preprocessed, unconventional training.
\end{itemize}
Next, these chosen combinations are tested with different regression algorithms in phase 2.

\begin{table}[htb]
    \begin{tabularx}{\textwidth}{|Y|L{0.08\textwidth}|L{0.10\textwidth}|L{0.08\textwidth}|L{0.08\textwidth}|L{0.12\textwidth}|}
        \hline
        \multicolumn{6}{|c|}{\textit{Message with feature hashing}} \\
        \hline
        \textbf{Algorithm} &
        \textbf{MAE} &
        \textbf{RMSE} &
        \textbf{RSE} &
        \textbf{RAE} &
        \textbf{CoD} \\ \hline
        Poisson PropT				& 3.1045				& 3.4232				& 1.0810				& 1.1087				& -0.0810  \\
        Poisson PropT NA 			& 3.0647			 	& 3.3359				& 1.0266			 	& 1.0945				& -0.0266  \\
        \hline
        Poisson UnconT				& 2.7530				& 3.4857			 	& 0.8329				& 0.8963			 	& 0.16704  \\
        Poisson UnconT NA 			& 2.7412				& 3.3489			 	& 0.7688				& 0.8924			 	& 0.23113  \\
        \hline
        NeuralNet PropT				& 2.9549				& 3.5045				& 1.1330				& 1.0553				& -0.1330  \\
        NeuralNet PropT NA			& 2.9368				& 3.4668				& 1.1087				& 1.0488				& -0.1087  \\
        \hline
        NeuralNet UnconT			& 3.629					& 4.6548			 	& 1.4854				& 1.1817			 	& -0.4854  \\
        NeuralNet UnconT NA 		& 3.7330				& 4.7398			 	& 1.5401				& 1.2154			 	& -0.5401  \\
        \hline
        Boosted PropT				& 2.2013				& 2.8158			 	& 0.7314				& 0.7861				& 0.26852  \\
        Boosted PropT NA			& 2.1983				& 2.7899				& 0.7180				& 0.7851				& 0.28193  \\
        \hline
        Boosted UnconT				& 3.0881				& 3.7033			 	& 0.9402				& 1.0054			 	& 0.05976  \\
        Boosted UnconT NA 			& 2.9448				& 3.4691			 	& 0.8250				& 0.9587			 	& 0.17494  \\
        \hline
        Linear PropT				& 2.9491				& 3.1988				& 0.9439				& 1.0532				& 0.05602  \\
        Linear PropT NA				& 2.8327			 	& 3.0956				& 0.8840			 	& 1.0117			 	& 0.11597  \\
        \hline
        Linear UnconT				& 2.8672				& 3.5982			 	& 0.8876				& 0.9335			 	& 0.11238  \\
        Linear UnconT NA 			& 2.6735				& 3.3376			 	& 0.7637				& 0.8704			 	& 0.23628  \\
        \hline
        \textbf{DecFor PropT}	 	& 2.4875			 	& 2.8611				& 0.7551				& 0.8883				& \textbf{0.24484}  \\
        DecFor PropT NA				& 2.85  		 		& 3.1922				& 0.9400				& 1.0178				& \textbf{0.05990}  \\
        \hline
        DecFor UnconT            	& 3.5236				& 4.3578				& 1.3493				& 1.1313				& -0.3493   \\
        DecFor UnconT NA         	& 4.0405				& 4.8958				& 1.7030				& 1.2972				& -0.7030	\\
        \hline
    \end{tabularx}
    \caption{Results of HML pipeline with different algorithms used in phase 2.
        Feature hashing has been used with \textbf{message}-column in each case.
        \textbf{Poisson} means \textit{Poisson regression},
        \textbf{NeuralNet} indicates \textit{Neural Network regression},
        \textbf{Boosted} means \textit{Boosted Decision Tree regression},
        \textbf{Linear} means \textit{Linear regression}, and
        \textbf{DecFor} means \textit{Decision Forest regression}.
        Each algorithm is tested with unconventional (\textbf{UnconT}) vs. proper training (\textbf{PropT}),
        and with or without anomaly probability values from phase 1 (\textbf{NA} means NoAnomalies).
        The most promising results are bolded.
    }
    \label{tab:results-msg-fhash-algorithm-comparison}
\end{table}

In table~\ref{tab:results-msg-fhash-algorithm-comparison},
we can see the results of different regression algorithms
with message data and feature hashing.
However,
as the results indicate,
comparison metrics do not improve with different algorithms.
Thus,
Decision Forest Regression is selected for the final validation
with fresh test data.

With rawmessage,
we were unable to execute tests with fresh data
because the model scoring module failed with an error,
stating that
\textit{\enquote{Number of unique values in column: 'rawmessage' is greater than allowed}}.
This happened
even though the rawmessage field was cleaned from the unique data values
such as timestamp and fingerprint.
For this reason,
we could not acquire test results of pipeline component combinations
that did not include rawmessage preprocessing.
With text preprocessing,
this issue did not occur.

\begin{table}[htb]
    \begin{tabularx}{\textwidth}{|Y|L{0.10\textwidth}|L{0.10\textwidth}|L{0.08\textwidth}|L{0.08\textwidth}|L{0.12\textwidth}|}
        \hline
        \multicolumn{6}{|c|}{\textit{Pure rawmessage}} \\
        \hline
        \textbf{Algorithm} &
        \textbf{MAE} &
        \textbf{RMSE} &
        \textbf{RSE} &
        \textbf{RAE} &
        \textbf{CoD} \\ \hline
        Poisson PropT		                & 2.7528		& 2.9170		& 1.0348		& 1.1261		& -0.0348   \\
        Poisson PropT NA	                & 2.7540		& 2.9185		& 1.0359		& 1.1266		& -0.0359	\\
        \hline
        Poisson UnconT                      & 2.2626		& 2.9650		& 0.8661		& 0.8927		& 0.13385 	\\
        Poisson UnconT NA                   & 2.3380		& 2.9977		& 0.8853		& 0.9225		& 0.11464 	\\
        \hline
        NeuralNet PropT		                & 2.3926		& 2.5209		& 0.7729		& 0.9788		& 0.22704   \\
        NeuralNet PropT NA	                & 2.3468		& 2.3981		& 0.6994		& 0.9600		& 0.30056   \\
        \hline
        NeuralNet UnconT                    & 2.8173		& 3.5439		& 1.2373		& 1.1116		& -0.2373 	\\
        NeuralNet UnconT NA                 & 2.3270		& 2.9708		& 0.8694		& 0.9181		& 0.13050 	\\
        \hline
        Boosted PropT		                & 2.75  		& 3.0103		& 1.1021		& 1.125 		& -0.1021   \\
        Boosted PropT NA	                & 2.75  		& 3.0103		& 1.1021		& 1.125 		& -0.1021   \\
        \hline
        Boosted UnconT                      & 2.8929		& 3.6821		& 1.3357		& 1.1414		& -0.3357 	\\
        Boosted UnconT NA                   & 2.7651		& 3.5996		& 1.2765		& 1.0910		& -0.2765 	\\
        \hline
        Linear PropT		                & 2.6982		& 2.8526		& 0.9896		& 1.1038		& 0.01030   \\
        Linear PropT NA		                & 2.6796		& 2.8188		& 0.9663		& 1.0962		& 0.03361   \\
        \hline
        Linear UnconT                       & 2.4777		& 3.0516		& 0.9174		& 0.9776		& 0.08254 	\\
        Linear UnconT NA                    & 2.3310		& 2.9720		& 0.8702		& 0.9197		& 0.12976 	\\
        \hline
        \textbf{DecFor UnconT }      & 2.9   			& 3.8200		& 0.7859	    & 0.7928	& \textbf{0.21402}		\\
        DecFor UnconT NA             & 3.0733			& 3.9588		& 0.8441		& 0.8402	& \textbf{0.15588}		\\
        \hline
        \textbf{DecFor PropT}       	& \textbf{1.3611}	& 1.8263		& 1.6678		& 1.0208	& -0.6678		\\
        DecFor PropT NA           	& \textbf{2.5833}	& 2.8694		& 4.1168		& 1.9375	& -3.1168		\\
        \hline
    \end{tabularx}
    \caption{Results of HML pipeline with different algorithms used in phase 2.
    Each case uses pure \textbf{rawmessage}-column without preprocessing.
    \textbf{Poisson} means \textit{Poisson regression},
        \textbf{NeuralNet} indicates \textit{Neural Network regression},
        \textbf{Boosted} means \textit{Boosted Decision Tree regression},
        \textbf{Linear} means \textit{Linear regression}, and
        \textbf{DecFor} means \textit{Decision Forest regression}.
        Each algorithm is tested with unconventional (\textbf{UnconT}) vs. proper training (\textbf{PropT}),
        and with or without anomaly probability values from phase 1 (\textbf{NA} means NoAnomalies).
        The most promising results are bolded.
    }
    \label{tab:results-rawmsg-fhash-algorithm-comparison}
\end{table}


\begin{table}[htb]
    \begin{tabularx}{\textwidth}{|Y|L{0.10\textwidth}|L{0.10\textwidth}|L{0.08\textwidth}|L{0.08\textwidth}|L{0.12\textwidth}|}
        \hline
        \multicolumn{6}{|c|}{\textit{Preprocessed rawmessage}} \\
        \hline
        \textbf{Algorithm} &
        \textbf{MAE} &
        \textbf{RMSE} &
        \textbf{RSE} &
        \textbf{RAE} &
        \textbf{CoD} \\ \hline
        Poisson PropT		                & 2.7540		& 2.9186		& 1.0360		& 1.1266		& -0.0360 	\\
        Poisson PropT NA	                & 2.7540		& 2.9185		& 1.0359		& 1.1266		& -0.0359 	\\
        \hline
        Poisson UnconT                      & 2.3714		& 3.0466		& 0.9144		& 0.9357		& 0.08556  \\
        Poisson UnconT NA                   & 2.3380		& 2.9977		& 0.8853		& 0.9225		& 0.11464  \\
        \hline
        NeuralNet PropT		                & 2.5653		& 2.6747		& 0.8701		& 1.0494		& 0.12986 	\\
        NeuralNet PropT NA	                & 2.3468		& 2.3981		& 0.6994		& 0.9600		& 0.30056 	\\
        \hline
        NeuralNet UnconT                    & 2.7686		& 3.4396		& 1.1656		& 1.0924		& -0.1656  \\
        NeuralNet UnconT NA                 & 2.3270		& 2.9708		& 0.8694		& 0.9181		& 0.13050  \\
        \hline
        Boosted PropT		                & 2.75  		& 3.0103		& 1.1021		& 1.125 		& -0.1021 	\\
        Boosted PropT NA	                & 2.75  		& 3.0103		& 1.1021		& 1.125 		& -0.1021 	\\
        \hline
        Boosted UnconT                      & 2.9566		& 3.6357		& 1.3022		& 1.1666   	    & -0.3022 \\
        Boosted UnconT NA                   & 2.7651		& 3.5996		& 1.2765		& 1.0910		& -0.2765 \\
        \hline
        Linear PropT		                & 2.6992		& 2.8546		& 0.9910		& 1.1042		& 0.00890 	\\
        Linear PropT NA		                & 2.6796		& 2.8188		& 0.9663		& 1.0962		& 0.03361 	\\
        \hline
        Linear UnconT                       & 2.2808		& 2.9685		& 0.8681		& 0.8999		& 0.13182  \\
        Linear UnconT NA                    & 2.3310		& 2.9720		& 0.8702		& 0.9197		& 0.12976  \\
        \hline
        \textbf{DecFor PropT }  		& \textbf{0.5277}		& 0.6328		& 0.2002	& 0.3958		& \textbf{0.79976}		\\
        DecFor PropT NA        		    & \textbf{2.5833}		& 2.8694	    & 4.1168	& 1.9375		& \textbf{-3.1168}		\\
        \hline
        \textbf{DecFor UnconT}    		& 2.9466				& 3.7159		& 0.7437	& 0.8056		& \textbf{0.25627}		\\
        DecFor UnconT NA             	& 3.0733				& 3.9588		& 0.8441	& 0.8402		& \textbf{0.15588}		\\
        \hline
    \end{tabularx}
    \caption{Results of HML pipeline with different algorithms used in phase 2.
    Each case uses preprocessed \textbf{rawmessage}-column.
    \textbf{Poisson} means \textit{Poisson regression},
        \textbf{NeuralNet} indicates \textit{Neural Network regression},
        \textbf{Boosted} means \textit{Boosted Decision Tree regression},
        \textbf{Linear} means \textit{Linear regression}, and
        \textbf{DecFor} means \textit{Decision Forest regression}.
        Each algorithm is tested with unconventional (\textbf{UnconT}) vs. proper training (\textbf{PropT}),
        and with or without anomaly probability values from phase 1 (\textbf{NA} means NoAnomalies).
        The most promising results are bolded.
    }
    \label{tab:results-prepros-rawmsg-fhash-algorithm-comparison}
\end{table}

As seen in tables~\ref{tab:results-rawmsg-fhash-algorithm-comparison} and~\ref{tab:results-prepros-rawmsg-fhash-algorithm-comparison},
Decision Forest regression gives the most promising results when using the rawmessage-column,
with or without text preprocessing.
Thus,
the initial component combinations were selected to further experimentation.

The final testing was executed with freshly acquired production data.
In the end,
only three of the most promising pipeline component combinations got tested in this phase.
The results are listed in table~\ref{tab:final-results}.
As seen from the final comparison metrics,
the results were not convincing.
Coefficient of determination was a negative number in each case,
meaning that our ML model did not find any sensible relationship between log data and ticket timestamps.
The negative value also indicates,
that even a random model would have performed better in ticket count estimation
than our trained algorithms.
Further examination of the score values behind these results
reveal a possible reason for this.
In case of preprocessed rawmessage, proper training and Decision Forest algorithm,
the MAE-value was 0.5277 and CoD-value 0.79976.
Without context,
these values would have been excellent,
meaning that an average error in ticket count estimations would have been slightly over 0.5 within a time frame.
However,
because the memory issue forced us to trim the data amount,
and the time frame compression condensed the training data in phase 2 even more,
the final evaluation was executed with just 3 rows of data.
Obviously,
this is not a sufficient amount of data to get reliable results.

\begin{table}[htb]
    \begin{tabularx}{\textwidth}{|Y|L{0.10\textwidth}|L{0.10\textwidth}|L{0.08\textwidth}|L{0.08\textwidth}|L{0.1\textwidth}|}
        \hline
        \multicolumn{6}{|c|}{\textit{Results with fresh test data}} \\
        \hline
        \textbf{Algorithm} &
        \textbf{MAE} &
        \textbf{RMSE} &
        \textbf{RSE} &
        \textbf{RAE} &
        \textbf{CoD} \\ \hline
        Decision Forest, message, feature hashing, proper training              & 1.7333		& 2.2899		& 1.2341		& 1.1470		& -0.2341   \\
        \hline
        Decision Forest, preprocessed rawmessage, unconventional training       & 3.4888		& 3.8921		& 3.5654		& 2.3088		& -2.5654	\\
        \hline
        Decision Forest, preprocessed rawmessage, proper training               & 4.25		    & 4.6840		& 5.1637		& 2.8125		& -4.1637 	\\
        \hline
    \end{tabularx}
    \caption{Final HML results with fresh test data.
    CoD-value in each case is negative,
        which means that the estimation power of the trained algorithms is weaker than random.
        Thus, these component combinations are not able to find the connection we were aiming for.
    }
    \label{tab:final-results}
\end{table}

After considering all the results,
it was determined that our initial goal to find a connection between log anomalies and technical ticket timestamps
did not succeed.
Even though we were not able to find the connection with the methods used in this study,
it should not be ruled out whether this connection exists or not.
Our final verdict is that further research is needed.

%% ************************************************************************************************************

\subsection{Improvement discussion}\label{subsec:discussion}

This research encountered several problems
that could not be anticipated beforehand.
Most notable of the problems was the memory issue
with Azure ML modules.
This,
along with the bureaucratic challenges regarding the data security,
forced us to limit the study scope in regards to the schedule of the thesis.
Thus,
several possibilities could not be examined thoroughly.

In order to use the results of this study in production,
the ML pipelines with trained algorithms should be published as online endpoints.
The data in production needed a great deal of processing before
it could be exported to the cloud environment.
To be able to use live production data for real time ticket estimation,
a solution for data processing and exporting would be needed.

The data format proved challenging,
not only because of the mixed type of data that included both CSV and JSON,
but also because of multiple different types of sensitive information
that had to be taken into account.
With more simple and consistent log formatting,
further insight into the data could have been acquired.
One major improvement could be the possibility to utilize the One-Class Support Vector Machine.
This, however,
would have needed a manually constructed dataset
including only "normal" log events,
or such events that can be reasonably assured
not to be related to the ticket inducing issues.
With more carefully preformatted data,
more informative log metrics could be found
which may have proven useful for algorithm estimations.

The time frame compression inevitably lost some information.
We attempted to minimize the drawbacks
by calculating multiple statistical values along with the compression.
Different approaches could still have been experimented with.
One possible approach could be calculating anomaly probability metrics per job ID
to increase the understanding of anomaly distribution inside time frames.
Due to the effects of the working week on the tickets,
shifting the time frames from Monday-Sunday to Saturday-Friday
could also change the results,
as it is presumable that tickets received early on Monday
are related to issues occurring during the weekend.

The original hypothesis was
that anomalous events in the logs
were clearly linked to the tickets received.
However,
as memory errors due to the size of data forced us to skip info-typed rows,
it is possible the data anomalies did not reflect to the tickets.
As stated before,
multiple error lines in the log may be linked to a single issue,
which could make the ticket inducing events
more common log feature.
Thus,
it could have been possible to get better results
by tuning the statistical values that were used
in a way that more common error messages would have been taken into account.

In this study,
we decided to skip some corners
and selected pipeline component combinations to continue
based on the initial results of Decision Forest regression algorithm.
The other algorithms were tested with
the combinations that worked best for the Decision Forest regression.
It is possible
that with different algorithms,
other component combinations would have worked better.
Additionally,
all of the algorithms have multiple tunable parameters
that affect the results greatly.
Most of the algorithms, however,
were used with default parameters
to save time and computing costs.
Model hyperparameter tuning and parameter combination testing
could still provide further results.

Finally,
without the memory issue limiting our data amount and component selection,
n-gram feature extraction could have been utilized to full extent.
Other data preprocessing methods were bound to lose valuable information,
and anomaly detection from the textual features in this study case
was not possible with the algorithms available.


\clearpage