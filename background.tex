%!TEX root = thesis.tex
%% %% ***************** Background *****************

\section{Background}\label{sec:background}
%\section{Aikaisempi tutkimus}

Machine learning, or ML,
is a subcategory of the AI field and data science.
Typically, ML refers to
a set of technologies used to \enquote{build computers
that improve automatically through experience}.\cite{jordan2015machine}
This is generally considered a machine way
to simulate human learning process.
ML usage has become more common
and is nowadays widely used in many fields,
not just in general information technology and computer science.
This is because data can be gathered everywhere,
and where there is data to be processed,
ML can be there to process it.
Computer algorithms are able to find 
statistical correlation and patterns
from places overlooked by human mind,
or where amount of data is just too much 
for people to process.
This is why ML has proved its power
in various empirical science fields,
such as biology, cosmology or social science.\cite{jordan2015machine}

In this section, 
key concepts of ML are explained briefly
and several ML features are explored 
that are most relevant to this study.
We also discuss shortly about data sensitivity
and how it had to be addressed during this study.

%% ************************************************************************************************************


\subsection{Machine learning field}\label{subsec:bg-ml-field}
%% TODO: Open up ML algorithms and learning methods

\subsubsection*{ML algorithms}
Algorithm means a finite sequence of (typically) mathematical operations
that are used to solve a specific problem, 
typically by repetition of some steps
until the problem resolves.\cite{merriam2022algorithm}
Algorithms are the main "magic" inside ML
where repeating patterns are searched from within the data
by iterating through all the data points.

In ML, 
algorithms can be generally divided into <four> categories
\todo{Check categories, create list or table}

Regression algorithms predict values
and are typically used with supervised learning.
\todo{Examples: House market price?}

Classification algorithms predict categories.
Depending on the algorithm,
they can predict between two or several categories.
\todo{Examples?}

Clustering algorithms use unsupervised learning
to find structures inside data.
\todo{Examples?}

Anomaly detection algorithms work also unsupervised
and try to find unusual or rare data points from data.
\todo{Examples?}

\todo{Something more generally about algorithms... Intro to next section (training).}

%% ************************************************************************************************************

\subsubsection*{ML training}
ML algorithms can be trained in two basic ways:
supervised and unsupervised learning.

In supervised learning,
algorithm is given data with ready answers on
how the data needs to be interpreted.
Algorithm then tries to figure out
how given data and the correct answers are related.

In unsupervised learning,
on the other hand,
algorithm does not get model data from which to train itself,
but instead it tries to find clusters or groups inside the data
that are linked together more closely than to other parts of data.
\todo{References!}

Typically,
when training an algorithm,
some predefined portion of the data
is used as training data.
\todo{Sources? Amounts?}
The rest is used to validate the results
so that validation data and training data do not overlap.
Instead, trained algorithm is given data it has not seen before
and the result it produces with it is then validated.
For example,
in supervised learning
the key values the algorithm is trained to find out
are hidden from the validation data.
The resulting values produced by the algorithm
are compared to those hidden values
and the difference between the estimate and the real value
can be used to determine how well the current algorithm compares to others.

\todo{Next one might change a bit depending on the actual results, which are still to be tested.}
However, in this study,
we are going to break that rule
about non-overlapping training and validation data.
The reason for this is explained further in section~\ref{subsec:meth-ml-pipeline})

%% ************************************************************************************************************

\subsection{Cloud ML platforms}\label{subsec:bg-cloud-ml-platforms}
\todo{Briefly about Azure, Google and AWS}

Machine learning algorithms are not light to operate.
Depending on the amount of data,
it can be a serious %% TODO: What? How big?
\todo{something something seriously big}

Especially with online applications
where real time analysis of new input data is required,
cloud computing resources can make a huge difference
in terms of processing speed. %% TODO: refs maybe?
\todo{referencing}

Online market offers several solutions for ML computing in cloud.
\todo{open up some facts about these. BRIEFLY}
Google

Amazon AWS(?)

Microsoft Azure\cite{altexsoft}

%% ************************************************************************************************************

\subsection{Azure ML Studio}\label{subsec:bg-azure-ml-studio-algorithms}

\todo{More info about Azure ML studio}
%% TODO!

\todo{Intro to next subsections}

%% ************************************************************************************************************

\subsection{Regression algorithm}\label{subsec:bg-regression-ml}
\todo{science and math behind regression algorithm }
%% TODO!

%% ************************************************************************************************************

\subsection{PCA-based anomaly detection}\label{subsec:bg-pca-ada}
\todo{Explain PCA and mention other ADA algorithms}

\todo{Something about Anomaly and Novelty detection differences?}

%% ************************************************************************************************************

\subsection{N-Gram features}\label{subsec:bg-ngram-features}
\todo{cover basic n-gram features and ML connection}

%% ************************************************************************************************************

\subsection{Data sensitivity}\label{subsec:bg-data-sensitivity}
\todo{some basic stuff about anonymization, data sensitivity and data protection}
\todo{Just practicalities, not much about theory or background}

%% ************************************************************************************************************

\subsection{Log data parsing with ML}\label{subsec:bg-log-data-parsing-with-ml}
\todo{Some research should exist}

%% ************************************************************************************************************

\clearpage
\todo{Is below topics needed? Would there be a better place for them?}

\subsection{Random delay (in time series?)}\label{subsec:bg-random-delay-in-time-series}
\todo{Anything about the topic?}
\todo{data in this research is not time-series data! eg. temperature would be}
%% However, random delay seems to be usually with time-series data

\subsection{Hybrid ML approach with anomaly detection?}\label{subsec:bg-hybrid-ml-approach-with-anomaly-detection}
\todo{Is there anything about this?}






\clearpage