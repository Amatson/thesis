%!TEX root = thesis.tex
%% %% ***************** Introduction *****************

%% ************************************************ 1 ************************************************

\section{Introduction}\label{sec:introduction}

%% Leave page number of the first page empty
\thispagestyle{empty}
%% TODO: Remember references
Artificial intelligence (AI) and machine learning (ML)
has found their way into
more and more fields of business.
In banking business they are already used in
fraud detection, risk management and service recommendations.\cite{donepudi2017machine}
Even though these
modern technologies utilizing big data
are widely used abroad,
AI and ML are not that popular in Finnish banking field.
Instead,
many self-acting solutions are being used
to streamline manual labor
which could be called intelligent,
but are merely highly automated processes
and thus cannot be included in the AI category.
One of these technologies used in Finnish banking systems
is Robotic Process Automation (RPA).

RPA operates \enquote{on the user interface of other computer systems
in the way a human would do},\cite{van2018robotic}
but is strictly bounded by predefined operations
thus being prone to unforeseen situations
such as faulty input.
RPA, like generally all other software,
produces log to \enquote{register
the automatically produced and time-stamped documentation
of events, behaviors, and conditions
relevant to a particular system}\cite{delarosa2018log}.
Logs don't have any standards or form guidelines to follow
which tends to make
log analysis and log based problem-solving troublesome.
This is also the case with RPAs developed by Oy Samlink Ab.

Oy Samlink Ab (Samlink from now on)
was founded in 1994
and is now owned by Kyndryl.
From the early years,
while going by the name of Samcom,
the company was owned by several Finnish banks
developing all sorts of IT solutions for them.
Nowadays,
Samlink offers a wide variety of banking solutions
from basic banking system to end user targeted software
such as Codeapp mobile application.

Besides banking,
Samlink develops multiple other IT solutions
to extensive range of customers,
for example
entertainment platform solutions for DNA\@.
Even though Samlink can be considered
a modern technology company,
the most modern AI technologies has not yet been adopted
in the variety of tools used in development.
However,
RPA has been actively used
in some banking solutions
to reduce the amount of manual labor required
from banking clerks.

In addition to continuous development
as well as product maintenance services,
Samlink also offers a technical help desk
regarding the software solutions produced.
As no IT solutions comes without bugs or misbehaviour,
Samlink service desk has to use considerable amount of labor
to resolve the possible reason
behind the technical support request tickets received.
In many cases,
the problem-solving starts by reading the log
and analyzing the data written by processes in question.

In this study,
we aim to find if it is possible to utilize
machine learning methods in analyzing logs
created by Samlink RPA's.
%% TODO: Check terms! RPA-robots? RPA-processes? How to define term hierarchy?
Ultimately,
we intend to train ML
which is able to predict the arrival of a technical support ticket
thus giving a warning for developers about possible issues
in the production.

%% TODO: What creates logs?

%% ************************************************************************************************************

\subsection{Background and motivation}\label{subsec:intro-background-and-motivation}
In the field of information technology
logging is one of the most important methods
in problem-solving,
be it software or operating system related.\cite{delarosa2018log}
Typically,
at least in Samlink processes,
logging is a bit more verbose
than it needs to be.
This is usually because when the problem occurs
it is easier to already have the verbose logs available
than trying to replicate the issue
after setting logging to more verbose mode.
Too verbose logging, however,
leads into two problematic issues for developers.

First of, the size of log is huge
and finding the critical parts
related to the problem in hand
takes more time.
Of course,
with more strict logging
pinpointing the issue from within the logs
would be faster,
but then again,
solving the problem with only critical error messages
could be more time-consuming
if crucial context is missing.

Secondly,
a well-designed software
is able to retry the process after first failure,
but logging is done in real time,
not after final results of the process has been determined.
This means,
that each process failure is logged
even though said process eventually succeeds.
Thus,
logs may include dozens of rows of information about a problem encountered,
which are not critical information after all.
These issues make log analyzing considerably laborious.

Production logs are usually not viewed
if everything is presumably working as intended.
Technical support tickets are both
last and most visible indicator
that something is wrong.
When a technical support ticket is received from banking clerks
it means that something is wrong
in a very visible way.
Roughly speaking,
technical tickets that are due to
clear misbehavior of the RPA systems
and not, for example, user errors,
can be divided into two categories.
First are the tickets
that uncover an unknown bug in the system
which can be either fixed
or instructed to user how to avoid.
Second type of tickets are
somewhat pre-known issues
that occur from time to time
and are either fixed with updating parts of the system
or by rebooting the process.

Typically,
in software systems,
if issue is known and can be fixed by rebooting something,
developers can create log monitors
that search for certain keywords
and raise an alert if encountered.
Developers can either run a reboot manually
after a log alert has been received
or set up an automated script to do it immediately
when such keyword has been found.
However,
when it comes to RPA's and technical tickets considering them,
it is hard to say what type of issue is in question
by reading the RPA logs word by word without context.
New kind of issues can be more frequent
than already confronted ones,
and clear keyword linked to
a certain problem may not exist
without considerable amount of false positive matches.

Machine learning algorithms are widely used
to find patterns from massive amount of data
making it an ideal tool for log analyzing.
Patterns, however,
need a connection to a visible issue to be useful.
If RPA system has encountered an error
but is able to retry successfully,
then no issue has practically happened
that needs immediate concern.
Hence,
RPA log analyzing with ML can find meaningful patterns
only if they relate to actual technical tickets.

If Samlink support has received a help request
the issue behind the request is not fresh anymore.
In the event of RPA job failing,
it takes some time for the clerk to notice the issue,
write a help request to first support level,
which then redirects the ticket to the corresponding team.
Furthermore,
if the issue is noticed during friday,
it takes few more days to be handled by RPA developers
due to weekend.
This leads to noticeable delay in processes
that were supposed to be dealt by RPA
but which now have to be manually taken care of
by said clerks.

If a correlation between logs and tickets received exists
and an ML algorithm is able to find it,
it could be possible to create an ML-based log analyzer
that can send an alert to developers
about an ongoing issue before banking clerks encounter it.
With automated scripts set up to receive such alerts,
some issues could even be fixed in the production
automatically without human interaction.
This would reduce significantly the time and labour needed
from developers and bank clerks alike. %% TODO: Check grammar

%% ************************************************************************************************************

\subsection{Research objectives}\label{subsec:intro-research-objectives}
This research aims to
pave the way for machine learning application developers
inside Samlink.
Multiple obstacles need to be tackled
as most of the phases in this study
has not yet been encountered inside the company.

First and foremost,
it is crucial to construct some basic rules
considering the format of log data
to make it usable by ML algorithms.
Log data formatting
is one of the key elements in automatic log analyzing applications
as it is not for just machines
but also for people to read.

As today more and more concern is set on anonymization
not only due to GDPR,
the data used for machine learning must be sanitized.
Because of this,
one major objective is to create a clean dataset
that is safe to use in cloud environment
without raising concern around security and privacy issues.
In addition to this,
data must also be clean enough
so that ML algorithms
are able to process it.

As mentioned,
Samlink has not yet developed ML applications.
In order to ease the %% TODO: käyttöönotto etc word here
for future ML application developers,
this study aims to document the process %% TODO: of käyttöönottoprosessi, set up?
well enough to create a simple guide to follow
in the possible future ML projects in Samlink.

Finally,
the main question this research is aiming to answer is:
\textit{is there such a correlation between RPA run logs and technical support tickets
that ML algorithm is able to find it,
and can this correlation be used to forecast a ticket arrival}?


%% ************************************************************************************************************

\subsection{Scope}\label{subsec:intro-scope}

In order to limit the study
to feasible length and content,
it is necessary to define the scope for the thesis.
Before diving in to the scope of research objectives,
we must first make one assumption regarding the data
that ML is going to find some meaning from.
In order to find a connection between log data and support tickets,
we make a hypothesis that errors leading to tickets
are visible to or parseable by ML algorithm.
In addition,
as we are going to utilize anomaly detection algorithm in log analyzing,
we must also assume that these errors in log
are, in fact, anomalies.
We will, however,
compare the results against these assumptions
to test this hypothesis.

%% ............................................................................................................

\subsubsection*{Data anonymization}
Anonymization in the context of this thesis
refers to data sanitization process
purposed to edit the data into
more secure form in the privacy point of view.
In this study
we aim to create a dataset usable in ML training.
In this respect,
anonymization is not in the main focus of the study
but only treated as a sub-phase
of the data preprocessing in whole.
Nevertheless,
anonymization is from the privacy perspective
the most important phase of data preprocessing.

Keeping this in mind,
anonymization is covered rather superficially,
only enough to explain the reasons
behind actions taken during anonymization process.

%% ............................................................................................................

\subsubsection*{Azure setup}
The ML training and result scoring
is done in Azure ML environment.
Azure is used for ML processes
because Samlink already had licenses in Azure Cloud
that are used for RPA process control.
Integrating existing Azure resources
with ML pipelines and endpoints constructed during this study
was seen as a big advantage.
Thus,
no other ML cloud provider was considered.
However,
other Azure competitors are mentioned to the extent
that their existence is recognised.

As one of the objectives is to create
an initial guideline for ML process commissioning
the Azure setup phase is documented in such detail
reflecting the importance of this information
for future developers
starting Azure ML projects in Samlink.

%% ............................................................................................................

\subsubsection*{Data requirements}
Data purity in a sense of
how easy it is to be used by ML algorithms
creates challenges at the beginning of ML training.
If data is not consistent,
has lots of missing values
or is formed in unanticipated way,
it requires considerable amount of preprocessing
slowing the training process
and causing errors in pipeline runs.

In order to create a baseline for Samlink ML projects
this study aims to give basic criterion
what is required from the data,
so it is easily analyzable by ML algorithms.

%% ............................................................................................................

\subsubsection*{Machine learning methods}
Several different machine learning algorithms exist
that are aimed for different applications in mind.
For example,
to make an algorithm that can predict
the price of an apartment listed\cite{winky}
we could be using linear regression,
and in order to detect
possible cyber threats from network traffic\cite{ghanem}
a two-class support vector machine could be utilized.
These two methods are very different in usage
and has their pros and cons in different applications.

As different methods can be used in creative ways
in very different applications
depending on how the data is presented
and how the ML problem is formed,
this study focuses on
just a few easily approachable training methods
that were seen suitable to answer the study objectives.

When it comes to anomaly detection algorithms (ADA),
only principal component analysis (PCA) is considered
because PCA-based Anomaly Detection component is the only one usable
from existing two anomaly detection algorithms
in Azure ML Studio.
As purely Azure ML Studio is used during this study,
no other anomaly detection algorithms are debated.
The other ADA-component,
One-Class Support Vector Machine,
is discussed briefly to explain its unsuitableness for current case.

%% TODO: maybe mention some other ADA-algorithms that exist even though not usable in Azure?

%% ************************************************************************************************************

\subsection{Structure}\label{subsec:intro-structure}

In the \textbf{Introduction} section
we explained the research motivation,
main objectives and study scope.
The next section, \textbf{Background},
explains %% TODO: Better word?
the general machine learning concepts
and terms relevant to this study case.
We also discuss these topics from the perspective of
existing studies. %% TODO: improve wording.

The third section,
\textbf{Research material and methods},
explains in detail the data format and contents
as well as the steps used to sanitize and preformat it
for ML algorithm training.
In addition,
resources needed to set up the ML designing and training environment
are discussed.
At the end of the section,
the ML pipelines used in the study are unfolded
as well as their contents explained in detail.

\textbf{Results} section reveals how the selected algorithms performed
and how well the research questions could be answered.

Finally,
in the section \textbf{Summary},
we summarize the research outcomes,
evaluate the results,
and discuss what could have been done better. %% TODO: More?

\clearpage


%% TODO! Use "Machine Learning" instead of "ML" in more places! Find relevant places to use!