%!TEX root = thesis.tex
%% %% ***************** Introduction *****************

%% ************************************************ 1 ************************************************

\section{Introduction}\label{sec:introduction}

%% Leave page number of the first page empty
\thispagestyle{empty}

Artificial intelligence (AI) and machine learning (ML)
have found their way into
more and more fields of business.
In the banking business they are already used in
fraud detection, risk management and service recommendations.\cite{donepudi2017machine}
Even though these
modern technologies utilizing big data
are widely used abroad,
AI and ML are not yet that commonly in the Finnish banking field.
Instead,
many self-acting solutions are used
to streamline manual labor
which could be called intelligent,
but are these solutions are merely highly automated processes
and thus cannot be included in the category of AI.\@
One of these technologies used in Finnish banking systems
is Robotic Process Automation (RPA).

RPA operates \enquote{on the user interface of other computer systems
in the way a human would do},\cite{van2018robotic}
but is strictly bounded by predefined operations,
which makes it prone to unforeseen situations
such as faulty input.
RPA, like generally all other software,
produces log to \enquote{register
the automatically produced and time-stamped documentation
of events, behaviors, and conditions
relevant to a particular system}\cite{delarosa2018log}.
Logs don't follow any standards or form guidelines
which tends to make
log analysis and log based problem-solving troublesome.
This is also the case with RPAs developed by Oy Samlink Ab.

Oy Samlink Ab (Samlink from now on)
was founded in 1994
and is now owned by Kyndryl.
From the early years,
while going by the name of Samcom,
the company was owned by several Finnish banks
for which it developed all sorts of IT solutions for them.
Nowadays,
Samlink offers a wide variety of banking solutions
from basic banking system to end user targeted software
such as Codeapp mobile application.

In addition to banking,
Samlink develops multiple other IT solutions
to an extensive range of customers,
for example
entertainment platform solutions for DNA\@.
Even though Samlink can be considered
a modern technology company,
the most modern AI technologies have not yet been adopted
as a part of the variety of tools used in development.
However,
RPA has been actively used
in some banking solutions
to reduce the amount of manual labor required
from banking clerks.

Along with continuous development
and product maintenance services,
Samlink also offers a technical help desk
regarding the software solutions it produces.
As no IT solution comes without bugs or misbehaviour,
Samlink's service desk has to use considerable amount of labor
to resolve the possible issue
behind the technical support request tickets received.
In many cases,
the problem-solving starts by reading the log
and analyzing the data written by the processes in question.

In this study,
we aim to find if it is possible to utilize
machine learning methods in analyzing logs
created by Samlink RPA's.
Ultimately,
we intend to train ML
which is able to predict the arrival of a technical support ticket
thus giving a warning for developers about possible issues
in the production.


%% ************************************************************************************************************

\subsection{Background and motivation}\label{subsec:intro-background-and-motivation}
In the field of information technology,
logging is one of the most important methods
in problem-solving,
be it software or operating system related.\cite{delarosa2018log}
Typically,
at least in Samlink's processes,
logging is more verbose
than it needs to be.
This is usually because when the problem occurs,
it is easier to already have the verbose logs available
than setting logging to more verbose mode and trying to replicate the issue.
Too verbose logging, however,
leads into two problematic issues for developers.

First of, the size of log is huge
and finding the critical parts
related to the problem in hand
takes more time.
Of course,
with stricter logging,
pinpointing the faulty event from within the logs
would be faster.
However,
solving the problem with only critical error messages
could be more time-consuming
if crucial context is missing.

Secondly,
a well-designed software
is able to retry the process after first failure,
but logging is done in real time regardless of the process result.
This means,
that each process failure is logged
even though said process might eventually succeed on later attempt.
Thus,
logs may include dozens of rows of information about a problem,
which is not critical information after all.
These issues make log analyzing considerably laborious.

Production logs are usually not viewed
if everything is presumably working as intended.
Technical support tickets are both
the last and most visible indicators of an issue in the system.
When a technical support ticket is received from banking clerks
it means that something is wrong
in a very visible way.
Roughly speaking,
there are two types of technical tickets
that are because of a clear misbehavior of the RPA system
(not, for example, due to a user error).\@
First are the tickets
that uncover an unknown bug in the system
which can be either fixed
or instructed to user how to avoid.
Second type of tickets are
somewhat pre-known issues
that occur from time to time
and are either fixed with updating parts of the system
or by rebooting the process.

Typically,
in software systems,
if an issue is known and can be fixed by rebooting something,
developers can create log monitors
that search for certain keywords
and raise an alert if they are encountered.
Developers can either run a reboot manually
after a log alert has been received
or set up an automated script to do it immediately
when such keyword has been found.
However,
when it comes to RPA's and technical tickets,
it is hard to say what the issue in question is
by reading the RPA logs word by word without context.
New kind of issues can be more frequent
than already confronted ones,
and a clear keyword linked to
a certain problem may not exist
without considerable amount of false positive matches.

Machine learning algorithms are widely used
to find patterns from massive amount of data
making ML an ideal tool for log analysis.
Patterns, however,
need a connection to a visible issue to be useful.
If the RPA system has encountered an error
but is able to retry successfully,
then no issue that requires immediate concern has actually happened.
Hence,
RPA log analyzing with ML can find meaningful patterns
only if they relate to actual technical tickets.

If Samlink support has received a help request
the issue behind the request is not fresh anymore.
In the event of RPA job failing,
it takes some time for the clerk to notice the issue,
write a help request to first support level,
which then redirects the ticket to the corresponding team.
Furthermore,
if the issue is noticed on friday,
it takes a few more days to be handled by RPA developers
due to the weekend.
This leads to a noticeable delay in processes
that were supposed to be dealt by RPA
but which now have to be manually taken care of
by clerks.

If a correlation between logs and received tickets exists
and an ML algorithm is able to find it,
it could be possible to create an ML-based log analyzer
that can alert developers
about an ongoing issue before banking clerks encounter it.
With automated scripts set up to receive such alerts,
some issues could even be fixed in the production
automatically without human interaction.
This would significantly reduce the time and labor needed
from developers and bank clerks alike.

%% ************************************************************************************************************

\subsection{Research objectives}\label{subsec:intro-research-objectives}
This research aims to
pave the way for machine learning application developers
inside Samlink.
Multiple obstacles need to be tackled
as most of the phases in this study
have not yet been encountered inside the company.

First,
it is crucial to construct some basic rules
considering the format of log data
to make it usable for ML algorithms.
Log data formatting
is one of the key elements in automatic log analysis applications
as it is not for just machines
but also for people to read.

As today more and more concern is set on anonymization,
the data used for machine learning must be sanitized.
As a consequence,
one major objective is to create a clean dataset
that is safe to use in a cloud environment
without raising concern around security and privacy issues.
In addition to this,
data must also be clean enough
so that ML algorithms
are able to process it.

As mentioned,
Samlink has not yet developed ML applications.
In order to facilitate deployment of applications
for future ML application developers,
this study aims to document the process of ML deployment
thoroughly enough to create a simple guide to follow
in possible future ML projects in Samlink.

Finally,
the main questions this research aims to answer are:
\textit{is there such a correlation between RPA run logs and technical support tickets
that an ML algorithm is able to find,
and can this correlation be used to forecast a ticket arrival}?


%% ************************************************************************************************************

\subsection{Scope}\label{subsec:intro-scope}

In order to limit the study
to feasible length and content,
it is necessary to define the scope for the thesis.
Before diving in to the scope of the research objectives,
we must first make one assumption regarding the data
from which ML is going to find some meaning.
In order to find a connection between log data and support tickets,
we make a hypothesis that errors leading to tickets
are visible to or parseable by ML algorithm.
In addition,
as we are going to utilize an anomaly detection algorithm in log analysis,
we must also assume that these errors on the log
are, in fact, anomalies.
The results will be compared against these assumptions
to the test this hypothesis.

%% ............................................................................................................

\subsubsection*{Data anonymization}
Anonymization in the context of this thesis
refers to a data sanitization process
purposed to edit the data into
a more secure form in the point of view of privacy.
In this study
we aim to create a dataset that can be used in ML training.
In this respect,
anonymization is not the main focus of the study
but only treated as a sub-phase
of the data preprocessing.
Nevertheless,
anonymization is the most important phase of data preprocessing
from the privacy perspective.

Keeping this in mind,
anonymization is covered rather superficially,
only enough to explain the reasons
behind actions taken during the anonymization process.

%% ............................................................................................................

\subsubsection*{Azure setup}
The ML training and result scoring
is done in Azure ML environment.
Azure is used for ML processes
because Samlink already had licenses for Azure Cloud
that is used for RPA process control.
Integrating existing Azure resources
with ML pipelines and endpoints constructed during this study
was seen as a big advantage.
Thus,
no other ML cloud provider was considered.
However,
other Azure competitors are mentioned to the extent
that their existence is recognised.

As one of the objectives is to create
an initial guideline for ML process commissioning,
the Azure setup phase is documented in such detail
reflecting the importance of this information
for future developers
starting Azure ML projects in Samlink.

%% ............................................................................................................

\subsubsection*{Data requirements}

Data purity in the perspective of machine learning algorithms
creates challenges at the beginning of ML training.
If data is not consistent,
has lots of missing values
or is formed in an unanticipated way,
it requires considerable amount of preprocessing
which slows the training process
and causes errors in pipeline runs.

In order to create a baseline for Samlink ML projects,
this study aims to give basic criteria for
what is required from the data,
so it is easily analyzable by ML algorithms.

%% ............................................................................................................

\subsubsection*{Machine learning methods}
Several different machine learning algorithms have been created
for different applications.
For example,
to make an algorithm that can predict
the price of a listed apartment\cite{winky}
we could use linear regression,
and in order create an algorithm that detects
possible cyber threats from network traffic\cite{ghanem},
a two-class support vector machine could be utilized.
These two methods are very different in usage
and have their pros and cons for different applications.

As different methods can be used in creative ways
in very different applications
depending on how the data is presented
and how the ML problem is formed,
this study focuses on
just a few easily approachable training methods
that were seen suitable to answer the study objectives.

When it comes to anomaly detection algorithms (ADA),
only principal component analysis (PCA) is considered
because PCA-based Anomaly Detection component is the only one
out of the two existing anomaly detection algorithms
that is usable in Azure ML Studio.
As only Azure ML Studio is used during this study,
no other anomaly detection algorithms are debated.
The other ADA-component,
One-Class Support Vector Machine,
is discussed briefly to explain its unsuitableness for the current case.


%% ************************************************************************************************************

\subsection{Structure}\label{subsec:intro-structure}

In the \textbf{Introduction} section
we explained the research motivation,
main objectives and scope of the study.
The next section, \textbf{Background},
clarifies the general machine learning concepts
and RPA terms relevant to this thesis.
We also discuss the mathematical theories
behind the most significant algorithms utilized in this study,
and the main methods that can be used to secure data privacy.

The third section,
\textbf{Research material and methods},
explains in detail the data format and contents
as well as the steps used to sanitize and preformat the data
for ML algorithm training.
In addition,
resources needed to set up the ML designing and training environment
are discussed.
This section is followed by \textbf{Machine learning pipeline structure},
which describes the ML pipelines set up during the study
and specifies their contents in detail.

The \textbf{Results} section compares how different algorithms performed
and how well the research questions could be answered.
Before that we discuss the memory issue
that affected greatly our component selections and data amounts.
At the end of the section we evaluate the results
and discuss what could have been done better.

Finally,
in the section \textbf{Summary},
we summarize the research goals and outcomes.

\clearpage
